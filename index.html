<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mohammad Mahdi Johari</title>

  <meta name="author" content="Mohammad Mahdi Johari">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./Johari_files/stylesheet.css">

  <link rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css">

</head>

<body data-new-gr-c-s-check-loaded="14.1079.0" data-gr-ext-installed="">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:69%;vertical-align:middle">
              <p style="text-align:center">
                <name>Mohammad Mahdi Johari</name>
              </p>
              <p>
                Hello! I am Mohammad Mahdi Johari, currently a Machine Learning Engineer at <a href="https://www.apple.com/">Apple</a>
                <i class="fa fa-apple"></i>, working on Apple Vision Pro.
              </p>
              <p>
                Prior to joining Apple, I finished my Ph.D. studies at <a href="https://www.epfl.ch/en/">EPFL</a> under
                the supervision of Prof. <a href="https://fleuret.org/francois/">Fran√ßois
                Fleuret</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:mjohari@apple.com">Email</a> &nbsp;/&nbsp;
                <a href="./Johari_files/Johari_CV.pdf">CV</a> &nbsp;/&nbsp;
                <!--<a href="data/ApoorvVyas-bio.txt">Biography</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=P9piTboAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
<!--                <a href="https://github.com/apoorv2904">Github</a> &nbsp;/&nbsp;-->
                <a href="https://twitter.com/mm_johari">Twitter</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/mm-johari/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
                <!--<a href="images/ApoorvVyas-circle.png"><img-->
              <a href="./Johari_files/personal.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="./Johari_files/personal.jpeg" class="hoverZoomLink">
              </a>
            </td>
          </tr>
        </tbody></table>

        <!--table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
            <td style="padding-left:2.5%; padding-top:0.5%; width:100%;vertical-align:middle; background-color:#FFFFE0">
                <p>
                    Expected gradutation in July 2022. Looking for summer research internship in 2021.
                </p>
            </td>
            </tr>
          </tbody>
        </table-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;padding-bottom:0px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                  I am interested in Machine Learning,
                  Computer Vision, and 3D Computer Vision.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;padding-bottom:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/ESLAM.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>ESLAM: Efficient Dense SLAM System Based on Hybrid Representation of Signed Distance Fields
              </papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="https://ch.linkedin.com/in/camilla-carta">C. Carta</a>,
              <a href="https://fleuret.org/francois/">F. Fleuret</a>
              </div>
              <em>CVPR (Highlight)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.11704">Paper</a> /
              <a href="https://github.com/idiap/ESLAM">Code</a> /
              <a href="https://www.idiap.ch/paper/eslam">Project Page</a>
              <!--a href="https://idiap.ch/~avyas/bib/arxiv-2020-lfmmi.txt">bibtex</a-->
              <p></p>
              <p>
                ESLAM is an efficient implicit neural representation method for Simultaneous Localization and Mapping (SLAM).
                <br>
                <br>

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/GeoNeRF.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>GeoNeRF: Generalizing NeRF With Geometry Priors
              </papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="https://www.linkedin.com/in/yann-lepoittevin-3380a75b/">Y. Lepoittevin</a>,
              <a href="https://fleuret.org/francois/">F. Fleuret</a>
              </div>
              <em>CVPR </em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2111.13539">Paper</a> /
              <a href="https://github.com/idiap/GeoNeRF">Code</a> /
              <a href="https://www.idiap.ch/paper/geonerf">Project Page</a>
              <!--a href="https://idiap.ch/~avyas/bib/arxiv-2020-lfmmi.txt">bibtex</a-->
              <p></p>
              <p>
                GeoNeRF is a generalizable photorealistic novel view synthesis method
                based on neural radiance fields.
                <br>
                <br>

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/DepthInSpace.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>DepthInSpace: Exploitation and Fusion of Multiple Video Frames for Structured-Light Depth Estimation
              </papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="https://ch.linkedin.com/in/camilla-carta">C. Carta</a>,
              <a href="https://fleuret.org/francois/">F. Fleuret</a>
              </div>
              <em>ICCV</em>, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Johari_DepthInSpace_Exploitation_and_Fusion_of_Multiple_Video_Frames_for_Structured-Light_ICCV_2021_paper.pdf">Paper</a> /
              <a href="https://github.com/idiap/DepthInSpace">Code</a> /
              <a href="https://www.idiap.ch/paper/depthinspace">Project Page</a>
<!--              <a href="https://idiap.ch/~avyas/bib/arxiv-2020-lfmmi.txt">bibtex</a>-->
              <p></p>
              <p>
                DepthInSpace is a self-supervised deep-learning method for depth estimation using a structured-light camera.
                <br>
                <br>

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/Context-Aware.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Context-Aware Colorization of Gray-Scale Images Utilizing a Cycle-Consistent Generative Adversarial Network Architecture</papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="http://ee.sharif.edu/~behroozi/">H. Behroozi</a>
              </div>
              <em>Neurocomputing</em>, 2020
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220306093">Paper</a>
<!--              <a href="https://idiap.ch/~avyas/pdfs/poster-neurips-2020.pdf">poster</a> /-->
<!--              <a href="https://clustered-transformers.github.io/blog">blog</a> /-->
<!--              <a href="https://colab.research.google.com/drive/1E8BYQf3Puxb643LOyIjT-0m3yXGO28ev?usp=sharing">-->
<!--              colab</a> /-->
<!--              <a href="https://github.com/idiap/fast-transformers">code</a> /-->
<!--              <a href="https://idiap.ch/~avyas/bib/neurips-2020.txt">bibtex</a>-->
              <p></p>
              <p>
                We propose a two-stage architecture for image colorization. The first stage generates an initial colored image and selects one of the specialist networks in the second stage which improves the quality of the colored image.
                <br>
                <br>

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/Colorization.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Gray-Scale Image Colorization Using Cycle-Consistent Generative Adversarial Networks with Residual Structure Enhancer</papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="http://ee.sharif.edu/~behroozi/">H. Behroozi</a>
              </div>
              <em>ICASSP</em>, 2020
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9054432">Paper</a>
<!--              <a href="https://youtu.be/KBWh7XCUAi8">video</a> /-->
<!--              <a href="https://idiap.ch/~katharas/pdfs/linear-transformers-slides.pdf">slides</a> /-->
<!--              <a href="https://colab.research.google.com/drive/1BV4OaWRAHYGeimO0cqHD86GfnfgUaKD4?usp=sharing">-->
<!--              colab</a> /-->
<!--              <a href="https://github.com/idiap/fast-transformers">code</a> /-->
<!--              <a href="https://idiap.ch/~avyas/bib/icml-2020.txt">bibtex</a>-->
              <p></p>
              <p>
                Proposing a cycle-consistent colorization model based on Generative Adversarial Network (GAN).
                <br>
                <br>

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="./Johari_files/Recurrence.jpg" width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Robust Airborne Target Recognition Based on Recurrence Plot Quantification of Micro-Doppler Radar Signatures
              </papertitle>
              <br>
              <br>
              <div class="author">
              <strong>M. M. Johari</strong>,
              <a href="http://ee.sharif.edu/~nayebi/en/index.html">M. M. Nayebi</a>
              </div>
              <em>IRS</em>, 2016
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/7497362">Paper</a>
<!--              <a href="https://github.com/idiap/pkwrap">code</a> /-->
<!--              <a href="https://idiap.ch/~avyas/bib/arxiv-2020-pkwrap.txt">bibtex</a>-->
              <p></p>
              <p>
                Proposing a method based on Recurrence Plot and Recurrence Quantification Analysis (RQA) to generate robust features against noise.
                <br>
                <br>

              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding-right:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </tbody></table>



<script>mendeleyWebImporter = {
  downloadPdfs(e,t) { return this._call('downloadPdfs', [e,t]); },
  open() { return this._call('open', []); },
  setLoginToken(e) { return this._call('setLoginToken', [e]); },
  _call(methodName, methodArgs) {
    const id = Math.random();
    window.postMessage({ id, token: '0.48943169343690407', methodName, methodArgs }, 'https://apoorv2904.github.io');
    return new Promise(resolve => {
      const listener = window.addEventListener('message', event => {
        const data = event.data;
        if (typeof data !== 'object' || !('result' in data) || data.id !== id) return;
        window.removeEventListener('message', listener);
        resolve(data.result);
      });
    });
  }
};</script></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
